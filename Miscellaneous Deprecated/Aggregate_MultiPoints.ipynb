{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "The **Aggregate_MultiPoints** script summarizes a set of point features allowing for these points to create an area and are used to calculate statistics. This results in a layer of displays of the number of points within each area.\n",
        "\n",
        "---\n",
        "\n",
        "The following libraries imported allow the code to run.\n",
        "> * **arcpy** - Allows to run all train and test scripts in an interactive environment.\n",
        ">* **env** - Accesses and uses the arcpy library to define variables in the env module.\n",
        ">* **re** - Regular expression or re, uses a set of strings or searches for a specific pattern.\n",
        ">* **Pandas** -  Used to model, analyze, and manipulate data sets.\n",
        ">* **arcpy.sa** import * - From the arcpy.sa module, the user can use the **arcpy.sa import** to use spatial analysis.\n",
        ">* **os** - Allows the creation and removal of directory folders, gathering data, and changing and finding the current directory. Users can also use **os** to interact with the operation systems.\n"
      ],
      "metadata": {
        "id": "HVcfS_sclLWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uWvkErlNbuZ"
      },
      "outputs": [],
      "source": [
        "# Libraries used\n",
        "import arcpy\n",
        "from arcpy import env\n",
        "import re\n",
        "import pandas as pd\n",
        "from arcpy.sa import *\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parent folder and the geodatabase name\n",
        "parent_folder = os.getcwd()\n",
        "geodatabase_name = \"example.gdb\""
      ],
      "metadata": {
        "id": "b9pv4tBORLoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create file *geodatabase_path*. If the file exists, it will print for the user to access. However, if the file does not exist, a new file will be created for the path.\n",
        "\n",
        "- The created workspace allows for variables to be placed on *geodatabase_path*. The *geodatabase_path* allows geoprocessing operations to process variables using arcpy as the default workspace. Set the parallel environment processing to = 0, where spatial analysis can be used. Multidimensional variables will not be used or false. The calculated results can be overwritten on an existing output file."
      ],
      "metadata": {
        "id": "5pcrn5q-8g8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the file geodatabase\n",
        "geodatabase_path = os.path.join(parent_folder, geodatabase_name)\n",
        "if os.path.exists(geodatabase_path):\n",
        "  print(geodatabase_path)\n",
        "else:\n",
        "  arcpy.CreateFileGDB_management(parent_folder, geodatabase_name)"
      ],
      "metadata": {
        "id": "C5MaIXd7SKDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the geodatabase as the workspace\n",
        "arcpy.env.workspace = geodatabase_path"
      ],
      "metadata": {
        "id": "7B-JXgV6Sqff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the environment\n",
        "arcpy.env.parallelProcessingFactor = 0\n",
        "arcpy.CheckOutExtension(\"Spatial\")\n",
        "acrpy.env.mathMultidimensionalVariable = False\n",
        "acrpy.env.overwriteOutput = True"
      ],
      "metadata": {
        "id": "wAgH5VVESykx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The user is asked to input the name of the data product and the point shape file that is used for the product.\n",
        "\n",
        "- An example would be:\n",
        ">*Enter the name of the data product:* **Cope**\n",
        "\n",
        "  >*Enter the name of the point shape file, you want to use:* **Cope_Grid_30_Points3**\n",
        "\n",
        "- These inputs are later used to create a file path, *gb_thirty_points*, and assigned the file to a variable called *table*. Using the *table* variable, a list is created with the field names containing fields that have the data product name. Next, a list is created named *fields*. The list *fields* is then used to create columns of a list of field names. Each column is created in a temporary list containing the column name and 'MEAN' which is appended to the temporary list under the *fields* list."
      ],
      "metadata": {
        "id": "Sh1JwrwVWI7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data product name\n",
        "product = input(\"Enter the name of the data product: \")\n",
        "\n",
        "# Select point file\n",
        "point_shape_name = input('Enter the name of the point shape file you want to use: ')\n",
        "gb_thirty_points = os.path.join(geodatabase_path, point_shape_name)"
      ],
      "metadata": {
        "id": "iy3-g2o3TGnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = gb_thirty_points\n",
        "\n",
        "# List the fields you want to include\n",
        "columns = [f.name for f in arcpy.ListFields(table) if f.type!=\"Geometry\" and product in f.name]\n",
        "print(columns)"
      ],
      "metadata": {
        "id": "b1u7ft3UWqQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = []\n",
        "for c in columns:\n",
        "  temp = [c, 'MEAN']\n",
        "  fields.append(temp)"
      ],
      "metadata": {
        "id": "z72DU3P-lqgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The user is asked to input the grid shape file path and name of the file. If it is not found, it will ask the user to input an acceptable name. The user will then input the output, **out_n**, to create a grid database name for the resolution.\n",
        "\n",
        "- An example would be:\n",
        ">*Enter the full file path and name of the grid shape file:* **E:\\\\share\\\\BIgRun\\\\Grids\\\\Grid_400.shp\\n**\n",
        "\n",
        "  >*Enter resolution of grid shape file:* **400**\n",
        "\n",
        "  >*Enter name of output:* **Cope_400**\n",
        "\n",
        "- Arcpy is used to convert the grid shape file to a feature class and aggregate points. These parameters include output name, polygon layer (grid database), and summary fields."
      ],
      "metadata": {
        "id": "07Q-_OxvnycW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grid_shape_file = input(\"Enter the full file path and name of the grid shape file: \")\n",
        "while not os. path.isfile(grid_shape_file):\n",
        "  print('The shapefile was not found.')\n",
        "  co = input(\"Please try again: \")\n",
        "\n",
        "# Set resolution\n",
        "out_n = input('Enter name of output: ')\n",
        "grid_db = 'Grid_'+ resolution\n",
        "arcpy.conversion.FeatureClassToFeatureClass(grid_shape_file, geodatabase_path, grid_db)\n",
        "\n",
        "arcpy.gapro.AggregatePoints(point_layer=gb_thirty_points, out_feature_class=out_n, polygon_or_bin='polygon', polygon_layer=grid_db, summary_fields=fields)"
      ],
      "metadata": {
        "id": "OKW50njuoYyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ask the user to input the output folder path, this is where the table will be saved. The arcpy will save the table as a CSV file and place the CSV file in the output folder.\n",
        "\n",
        "- An example would be:\n",
        ">*Enter output folder path for the table:* **E:\\\\share\\\\BIgRun\\\\Tables**"
      ],
      "metadata": {
        "id": "COrVOlh6peP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_folder = input('Enter output folder path for table: ')\n",
        "arcpy.conversion.TableToTable(out_n, out_folder, out_n + '.csv')"
      ],
      "metadata": {
        "id": "Y0IRswhupr5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
