# -*- coding: utf-8 -*-
"""inst_post_process.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15LLK0wlfGeLg2fTMB8U3LNKnEJtDnEW2

#Introduction
This **inst_post_process** program organizes data provided in a specific file that the user requests information from. This gives the user the ability to arrange and organize data from the stations and other data that the user is searching for.

---
The following libraries are imported to allow the code to be run:

* **os** - The directory service provides the ability to create and remove directory folders, gather data, change and find the current directory, and provide a means for users and the operating system to interact with each other.
* **datetime** - Manipulates the data between dates and time.
* **seaborn** - Statistical graphs.
* **matplotlib.pyplot** - Creates data visualization (i.e. graphs)
* **string** - Allows strings or data to be split when needed.
* **warnings** - Informs the user of the state of the code or where an error has occurred.
* **sys** - Provides a way to manipulate the runtime of the program by using certain parameters and functions.
* **Pandas** - Is a tool for modeling, analyzing, and manipulating data sets.
> For more information visit: https://www.geeksforgeeks.org/introduction-to-pandas-in-python/#
* **NumPy** - Supports analysis and can perform operations on a large set of data.
> For more information visit: https://numpy.org/doc/stable/user/whatisnumpy.html
* **re** - regular expression (or **re**) specifies a set of strings, where a particular string will match the given regular expression.
> For more information visit: https://docs.python.org/3/library/re.html

**natsort**

---
* **natsorted** - Sorts strings and numbers separately.

**sklearn.preprocessing**

---
* **StandardScaler** - Removes the mean or average value and scales to the unit variance.

**sklearn.model_selection**

---


* **train_test_split** - Splits arrays into random train and test subsets which provides valid results.
"""

import os
import datetime
import seaborn as sns
import matplotlib.pyplot as plt
import string
import warnings
import sys
import pandas as pd
import numpy as np
import re
from natsort import natsorted
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""- The user will be asked to input the dataset name, the input directory, and
the output directory to initialize the program.
"""

# Set data product name
d_name = input("Enter the name of the dataset (Include file extension): ")

# Set the input directory
input_dir = input("Enter the input directory: ")

# Set the output directory
output_dir = input("Enter the output directory: ")

"""- The program will open and read the file, "station_pagenames". The file's contents will be stored in the variable titled *stattion_p_file*.

- The code performs two tasks simultaneously: running and checking for the file's existence. If the file is not found, the code engages the user in a prompt loop until a valid file is provided.

- After the file is prepared, it will be divided into a list of the *pagenames*, then the program stores the variables in *stattion_p*.
"""

stattion_p_file = open("station_pagenames","r")

while not os.path.exists(stattion_p_file):
  print('The station_pagenames list txt was not found. It should be in the same directory as the .py script. ')
  n = input("Press enter to try again.")
  stattion_p_file = open("station_pagenames","r")

stattion_p = stattion_p_file.read().split(',')

"""- The program will open and read the text file, "station_names.txt". The file's contents will be stored in the variable titled *stattion_n_file*.

- The code performs two tasks simultaneously: running the code and checking for the file's existence. If the file is not found, the code engages the user in a prompt loop until a valid file is provided.

- After the file is prepared, it will be divided into a list of the station names, then the program stores the variables in *stattion_n*.
"""

stattion_n_file = open("station_names.txt","r")

while not os.path.exists(stattion_n_file):
  print('The station_names.txt list txt was not found. It should be in the same directory as the .py script. ')
  n = input("Press enter to try again.")
  stattion_n_file = open("station_names.txt","r")

stattion_n = stattion_n_file.read().split(',')

"""- The variable *data* was created to read the constructed full path of the dataset from the input directory (*input_dir*) and the name of the dataset (*d_name*)."""

data = pd.read_csv(os.path.join(input_dir, d_name))

"""# *Variables*

---



- It is important to create and upload a  text file list (**.csv**, comma-separated-values) containing the names of all the variables (including the target variable).

- Given that the variable names can vary depending on the user's data, it is more convenient to create a separate file with the variable names and then adjust them to the code.

- An example of the list of variables would be:
> *'Clay'*, *'Sand'*, *'Silt'*, *'Elevation'*, *'Ascept'*, *'Slope'*, *'LAI'*, *'SMERGE'*, *'NDVI'*, *'Albedo'*, *'Temp'*, *'Date'*, *'ML_'*, *'PageName'*, *'Station'*
"""

variables = input("Enter the name of the variables list (make sure the file is in the text file format): ")
variables_file = os.path.join(input_dir, variables)

while not os.path.exists(variables_file):
  variables = input("The variables list txt as not found, it should be in the home directory, try again. ")
  variables_file = os.path.join(input_dir, variables)

"""- Input the name of the index variable, which will be integrated in the output dataframe."""

index_variable = input("Enter the index variable from the list of variables: ")

"""# *Date Formatting*

---


- The *Date* column will convert to a datetime object using the *pd.to_datetime* function.

  > **Note**: This section only allows three types of date formats: "*%m/%d/%Y*", "*%Y/%m/%d*", and "*%Y/%j*". If you are using another type of format make sure to change it to one of those formats beforehand.
"""

#data['Date'] = pd.to_datetime(data['Date'], format = '%m%d%Y')

def date_formatting(data):
  date_format = input('If file uses "%m/%d/%Y" type: A, if "%Y/%m/%d" type: B, else "%Y/%j" type: C : ')

  while date_format != 'A' and date_format != 'B' and date_format != 'C':
    date_format = input('INPUT ERROR. If file uses "%m/%d/%Y" type: A, if "%Y/%m/%d" type: B, else "%Y/%j" type: C')

  if date_format == 'A':
    data['Date'] = pd.to_datetime(date['Date'], format = "%m/%d/%Y")
    data['Date'] = data['Date'].astype(int)

  if date_format == 'B':
    data['Date'] = pd.to_datetime(date['Date'], format = "%Y/%m/%d")
    data['Date'] = data['Date'].astype(int)

  if date_format == 'C':
    data['Date'] = pd.to_datetime(date['Date'], format = "%Y/%j")
    data['Date'] = data['Date'].astype(int)

  return data

  data = date_formatting(data)

"""- A new empty DataFrame, ***out***, is created by concatenating data from the larger DataFrame, ***data***, that is based on the station names, *stattion_p*."""

p = len(stattion_p)
out = pd.DataFrame(columns = variables)

"""- The subsequent code will perform the following steps for every station ID available in the *stattion_p* list:
  - **filter the data**: The ***data*** DataFrame will be used to select rows, where the *index_variables* column matches the current station ID, *stattion_p[q]*.
  - **updating the station name**: The *stattion_n* will be used to update the values in the '*Station*' column of the filtered DataFrame with the corresponding station name.
  - **reset the index**: Reset the index of the DataFrame to be sequential.
  - **concatenate the DataFrame**: Will concatenate the DataFrame with the ***out*** DataFrame.
"""

for q in range(0, p):
  inst = data[index_variable == stattion_p[q]]
  inst['Station'] == stattion_n[q]
  inst.reset_index(inplace=True)

  out = pd.concat([out,inst])

# Sort the DataFrame by 'Station' and 'Date' columns
out.sort_values(by=['Station', 'Date'], inplace = True)

# Drop the index_variable column
out.drop(columns = index_variable, inplace = True)

# Print the full path of the input directory (input_dir) and the name of the dataset (d_name)
print(os.path.join(input_dir, d_name))

# Save the DataFrame to a new CSV file with a different name
out.to_csv(os.path.join(input_dir, d_name.replace('.csv','inst.csv')), index=False)