# -*- coding: utf-8 -*-
"""static_var_gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tlWhKn0WW7-1hivuhAp-KzpWQccTV_Y8

#Introduction

The **static_var_gen** program enables users to generate a new CSV file that leverages static variables from the original dataset. This is achieved by constructing home paths and the name of the dataset containing the static data. The program then verifies the existence of the file. This functionality aids users in creating a file that tracks related data and allows for the display of a table containing the aforementioned data.

---
The following libraries imported to allow the code to be run:
* **os** - The directory service provides the ability to create and remove directory folders, gather data, change and find the current directory, and provide a means for users and the operating system to interact with each other.
* **datetime** - Manipulates the data between dates and time.
* **modin.pandas** - Distributes and computes data faster by using API.
* **matplotlib.pyplot** - Creates data visualization (i.e. graphs)
* **seaborn** - Statistical graphs.
* **string** - Allows strings or data to be split when needed.
* **warnings** - Informs the user of the state of the code or where an error has occurred.
* **sys** - Provides a way to manipulate the runtime of the program by using certain parameters and functions.
* **Pandas** -  Is a tool for modeling, analyzing, and manipulating data sets.
> For more information visit: https://www.geeksforgeeks.org/introduction-to-pandas-in-python/#
* **Numpy** - Supports analysis and can perform operations on a large set of data.
> For more information visit: https://numpy.org/doc/stable/user/whatisnumpy.html
* **re** - regular expression (or **re**) specifies a set of strings, where a particular string will match the given regular expression.
> For more information visit: https://docs.python.org/3/library/re.html

**natsort**

---


* **natsorted** - Sorts strings and numbers separately.




**sklearn.preprocessing**

---


* **StandardScaler** - Removes the mean or average value and scales do the unit variance.

**sklearn.model_selection**

---


* **train_test_split** - Splits arrays into random train and test subsets which provides valid results.
"""

import os
import datetime
import modin.pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import string
import warnings
import sys
import pandas as pd
import numpy as np
import re
from natsort import natsorted
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""- Paths will be constructed based on the zone and name.

  An example would be the following:
  > *Enter the home directory where the datasets are located: /content/AIRMOSS/*
"""

# Constructing home paths
home = input("Enter the home directory where the datasets are located: ")

"""- The **static_file** variable is created by using the inputs of the home directory and the name of the static dataset.

- Input the name of the dataset that contains the static data, this will be used to construct the full path.

- While the code is running it will also be checking if the testing file exists. If the file does not exist, then the code will prompt the user until a valid file is provided.
"""

# Asking for the name of the training dataset and constructing the full path
static_dataset_name = input("Enter the name of the dataset containing static data (including file extension): ")

static_file = os.path.join(home, static_dataset_name)

while not os.path.exists(static_file):
  print(static_file + "does not exist. Please enter the correct dataset name. ")
  static_dataset_name = input("Enter the name of the dataset containing static data (including file extensions): ")
  static_file = os.path.join(home, static_dataset_name)

"""- Input the name of the index variable."""

index_var = input("Enter the index variable from the list of variables: ")

"""- The columns are printed using the **static_file** that was generated, as long as the empty variable '*i*' does not equal '*exit* '. These columns are then added to the **static_vars** variable. Finally, the user gives the **static_vars** dataset a name, which is saved as a file."""

i = ''
static_vars = [index_var]

# Reads static_file
data = pd.read_csv(static_file)
print('These are the column names of the given table, which columns are the static variables. Type "exit" when finished. The Pagename column will automatically be added. ')
print(data.columns)
while i != 'exit':
  i = input(': ')
  if i != 'exit':
    static_vars.appen(i)

# Constructing file name
name = input("Enter the name of the dataset (NOT including file extension): ")
static = data[static_vars]
static.to_csv(os.path.join(home, name + '_static.csv'), index = False)static